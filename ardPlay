#!/usr/bin/env python3
from urllib.parse import urlparse, parse_qs	
from xml.dom.minidom import parseString
from lxml import etree
from slimit import ast
from slimit.visitors import nodevisitor
import urllib.request
import urllib.parse
import slimit
import sys
import shlex
import subprocess
import json
import re
import datetime

PLAYER = '/usr/bin/mplayer'
API_URL = 'https://api.ardmediathek.de/public-gateway?variables={variables}&extensions={extensions}'
API_VARIABLES = {
	'client': 'ard',
	'clipId': '',
	'deviceType': 'pc'
}
API_EXTENSIONS = {
	'persistedQuery': {
			'version':1,
			'sha256Hash':'38e4c23d15b4b007e2e31068658944f19797c2fb7a75c93bc0a77fe1632476c6'
		}
}
CMD_TPL = '{:s} "{:s}"'

def format_duration(seconds):
	"""
	Stole from: http://www.voidcn.com/article/p-qlzvdfdd-c.html
	"""
	if seconds == 0: return "now"
	origin = seconds
	dic = {
		'year': 60 * 60 * 24 * 365,
		'day': 60 * 60 * 24,
		'hour': 60 * 60,
		'minute': 60,
		'second': 1
	}
	spent = {}
	ans = ""
	for x in ['year','day','hour','minute','second']:
		spent[x] = seconds // dic[x]
		ans += "{}{} {}{}".format('' if seconds == origin else ' and ' if seconds % dic[x] == 0 else ', ',spent[x],x,'s' if spent[x] > 1 else '') if spent[x] > 0 else ''
		seconds %= dic[x]
	return  ans

class ArdMediaHolder(object):

	def __init__(self):
		self._holder = []
		self._js = {}

		# metadata information
		self._title = ''
		self._channel = ''
		self._contentId = 0
		self._clipLength = 0

		self._geoBlocked = None
		self._blockedByFsk = None
		self._broadcastOn = None
		self._availableUntil = None

	def appendJs(self, key, value):
		if value._relevant:
			self._js[key] = value

	def append(self, quality, uri):
		self._holder.append({
			'_quality': quality,
			'_stream': uri
		})

class ArdVisitorElement(object):

	def __init__(self, key, callback):
		self._key = key
		self._cb = callback
		self._type = None
		self._quality = None
		self._urls = []
		self._relevant = False

	def parse(self, node):
		for child in node.right.children():
			if str(child.left.value) == '"__typename"':
				self._type = child.right.value.replace('"', '')
				if self._type == 'MediaStreamArray':
					self._relevant = True
			elif str(child.left.value) == '"_quality"':
				self._quality = child.right.value.replace('"', '')
			elif str(child.left.value) == '"_stream"':
				self._parseMedia(child.right)

		if self._quality and self._urls:
			for u in self._urls:
				getattr(self._cb, 'append')(self._quality, u)

	def _parseMedia(self, node):
		for child in node.children():
			if str(child.left.value) == '"json"':
				for u in child.right.children():
					stream = u.value[1:-1]
					try:
						stream = urllib.parse.unquote(stream)
					except Exception as e:
						print(str(e))
						pass
					else:
						stream = stream.replace('\\u002F', '/')
					self._urls.append(stream)

class ArdVisitor(nodevisitor.ASTVisitor):
	def visit_Object(self, node):
		for prop in node:
			left, right = prop.left, prop.right
			if self.callback:
				try:
					getattr(self.callback, 'appendJs')(left.value, right.value)
				except AttributeError:
					ave = ArdVisitorElement(left.value, self.callback)
					ave.parse(prop)
					getattr(self.callback, 'appendJs')(left.value, ave)

def parsePublicApi(clipId):
	ext = json.dumps(API_EXTENSIONS, separators=(',', ':'))
	API_VARIABLES['clipId'] = clipId
	var = json.dumps(API_VARIABLES, separators=(',', ':'))
	cusHeaders = {
		'TE': 'Trailers',
		'Origin': 'https://www.ardmediathek.de',
		'content-type': 'application/json',
		'Accept': '*/*',
		'User-Agent': 'monobear.business Crawler'
	}

	# first send OPTIONS
	respOptions = urllib.request.urlopen(urllib.request.Request(API_URL.format(variables=var, extensions=ext), headers=cusHeaders, method='OPTIONS'))

	req = urllib.request.Request(API_URL.format(variables=var, extensions=ext), headers=cusHeaders)
	r = urllib.request.urlopen(req, timeout=2)
	if r.code != 200:
		sys.stderr.write('Could not retrieve stream informations.\n')
		sys.exit(1)

	# now we need to extract some data.
	js = json.loads(r.read().decode('utf-8'))
	holder = ArdMediaHolder()
	for sa in js['data']['playerPage']['mediaCollection']['_mediaArray']:
		for media in sa['_mediaStreamArray']:
			for stream in media['_stream']:
				# try to decode first!
				streamDecoded = stream
				try:
					streamDecoded = urllib.parse.unquote(stream)
				except:
					pass
				holder.append(media['_quality'], streamDecoded)

	# some meta information?
	holder._title = js['data']['playerPage']['title']
	holder._clipLength = js['data']['playerPage']['tracking']['atiCustomVars']['clipLength']
	holder._contentId = js['data']['playerPage']['tracking']['atiCustomVars']['contentId']
	holder._channel = js['data']['playerPage']['tracking']['atiCustomVars']['channel']
	holder._blockedByFsk = js['data']['playerPage']['blockedByFsk']
	holder._geoBlocked = js['data']['playerPage']['geoblocked']
	holder._broadcastOn = datetime.datetime.strptime(js['data']['playerPage']['broadcastedOn'], '%Y-%m-%dT%H:%M:%SZ')
	holder._availableUntil = datetime.datetime.strptime(js['data']['playerPage']['availableTo'], '%Y-%m-%dT%H:%M:%SZ')

	if holder._holder:
		printStreams(holder, True)
	else:
		sys.stderr.write('Could not find any stream.\n')
		sys.exit(1)

def parseHtmlDom(url):
	url = url.strip()
	req = urllib.request.Request(url)
	r = urllib.request.urlopen(req)
	if r.code != 200:
		sys.stderr.write('Could not retrieve stream informations.\n')
		sys.exit(1)

	# now we need to extract some data.
	playerPage = r.read().decode('utf-8')
	parser = etree.XMLParser(recover=True)
	root = etree.fromstring(playerPage, parser)
	dom = parseString(etree.tostring(root))
	script = ''
	for s in dom.getElementsByTagName('script'):
		if '__APOLLO_STATE__' in s.toxml():
			for c in s.childNodes:
				script += c.wholeText

	if script:
		for line in script.split('\n'):
			line = line.strip()
			if line and '__APOLLO_STATE__' in line:
				var, value = line.split(' = ', 1)
				p = slimit.parser.Parser()
				tree = p.parse(line)
				visitor = ArdVisitor()
				holder = ArdMediaHolder()
				visitor.callback = holder
				visitor.visit(tree)

				if holder._holder:
					printStreams(holder, True)
				else:
					sys.stderr.write('Could not find any stream.\n')
					sys.exit(1)
	else:
		sys.stderr.write('Could not parse or find script block.\n')
		sys.exit(1)

def parseArg(url):
	# two variants we can try right now:
	# extract the clip id here:
	clipIdRe = re.compile(r'^http(s)?://(.*)/(?P<clipid>[a-zA-Z0-9]+)/.*$')
	clipMatch = clipIdRe.match(url)
	if clipMatch:
		clipId = clipMatch.group('clipid')
		try:
			parsePublicApi(clipId)
		except:
			sys.stderr.write('Fallback to html DOM parsing.\n\n')
			parseHtmlDom(url)
	else:
		parseHtmlDom(url)

def printStreams(streams, play=False):
	# do we have some kind of meta information?
	if streams._title:
		titleMsg = '{channel}: {title} ({clipLength})'.format(
				channel=streams._channel,
				title=streams._title,
				clipLength=format_duration(streams._clipLength)
			)
		print(titleMsg)
		print('-'*len(titleMsg) + '\n')

	i = 0
	streamNumbered = []
	availableQualities = []
	# get title of that language.
	for metaStream in streams._holder:
		qualKey = 'MQ'
		if metaStream['_quality'] == '0':
			qualKey = 'MQ'
		elif metaStream['_quality'] == '1':
			qualKey = 'HQ'
		elif metaStream['_quality'] == '2':
			qualKey = 'EQ'
		elif metaStream['_quality'] == '3':
			qualKey = 'SQ'
		elif metaStream['_quality'] == 'auto':
			qualKey = 'auto'
		if qualKey not in availableQualities:
			availableQualities.append(qualKey)

	knownQuals = []
	for qual in ['auto', 'XQ', 'MQ', 'HQ', 'EQ', 'SQ']:
		if qual in availableQualities:
			knownQuals.append(qual)
	# we need to resort the qualStreams.
	for quality in knownQuals:
		print(quality + ':')
		for metaStream in streams._holder:
			qualKey = 'MQ'
			if metaStream['_quality'] == '0':
				qualKey = 'MQ'
			elif metaStream['_quality'] == '1':
				qualKey = 'HQ'
			elif metaStream['_quality'] == '2':
				qualKey = 'EQ'
			elif metaStream['_quality'] == '3':
				qualKey = 'SQ'
			elif metaStream['_quality'] == 'auto':
				qualKey = 'auto'
			if qualKey == quality: 
				playNo = ''
				streamList = []
				streamList.append(metaStream['_stream'])

				for streamEntry in streamList:
					if streamEntry.startswith('//'):
						streamEntry = 'https:' + streamEntry
					if play:
						playNo = '[{:>2d}] '.format(i)
						streamNumbered.append(streamEntry)
						i += 1
					print('    ' + playNo + ': ' + streamEntry)
		print(' ')

	# some more information available?
	if streams._blockedByFsk:
		print('This media is restricted by FSK!')
	
	if streams._broadcastOn and streams._availableUntil:
		print(
			'Media is casted on {broadcast}Z and available until {available}Z'.format(
				broadcast=streams._broadcastOn.strftime('%d.%m.%Y %H:%M:%S'),
				available=streams._availableUntil.strftime('%d.%m.%Y %H:%M:%S')
			)
		)
	elif streams._broadcastOn:
		print(
			'Media is casted on {broadcast}Z.'.format(
				broadcast=streams._broadcastOn.strftime('%d.%m.%Y %H:%M:%S')
			)
		)
	elif streams._availableUntil:
		print(
			'Media is available until {available}Z.'.format(
				available=streams._availableUntil.strftime('%d.%m.%Y %H:%M:%S')
			)
		)

	print(' ')

	if play:
		playNo = input('> ')
		if playNo.strip().lower() == 'q':
			print('Bye, bye!')
		else:
			try:
				playNo = int(playNo.strip())
			except ValueError:
				sys.stderr.write('Invalid number given. Cancel.\n')
			else:
				if playNo < 0:
					sys.stderr.write('Invalid number given. Cancel.\n')
				else:
					try:
						streamUrl = streamNumbered[playNo]
					except KeyError:
						sys.stderr.write('Stream # not existant.\n')
					except IndexError:
						sys.stderr.write('Stream # not existant.\n')
					else:
						cmd = CMD_TPL.format(PLAYER, streamUrl)
						subprocess.run(cmd, shell=True, check=True)

if __name__ == '__main__':
	pp = None
	if len(sys.argv) > 2:
		sys.stderr.write('Give me only ONE url!\n')
		sys.exit(1)
	elif len(sys.argv) < 2:
		sys.stderr.write('You have to pass an url!\n')
		sys.exit(1)
	else:
		pp = parseArg(sys.argv[1])
